\documentclass[a4paper,12pt]{article}
\begin{document}
\title{Stability of Deep Neural Networks}
\author{Antoine Hebert, Ribal Aladeeb, Tristan Glatard, Yohan Chatelain}
\maketitle
\section{Introduction}
\paragraph{In the last decade, Deep Learning has proven to be one of the most
	powerful techniques for solving machine learning problems both in academia
	and industry. However Deep Learning is not immune to the reproducibility
	problems encountered in the scientific community. For this reason we are
	interested in evaluating how numerically stable neural networks are. We
	mainly focus on two basic classification use cases of neural networks: MNIST
	and CIFAR10. Our aim is to run Monte Carlo Simulations during the inference phase
	on networks trained for solving the aforementioned use cases. In this way we approximate the number of signifigant digits in the output predictions.}
\section{Methods}

\paragraph{
    start of methods
}
\subsection{NumPy}
\subsection{FrugallyDeep}
\subsection{PyTorch}
\section{Results}
\end{document}